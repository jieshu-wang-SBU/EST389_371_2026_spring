{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Read and Write Files using Pandas\n",
    "\n",
    "## Read csv files\n",
    "\n",
    "- Relative path: are partial and depend on the current working directory\n",
    "    - A single dot (./ or just the filename) refers to the current working directory.\n",
    "    - Two dots (../) move one level up in the directory hierarchy.\n",
    "    - Directory names separated by forward slashes (/) navigate into subfolders\n",
    "    - Sometimes, depending on your IDE, you might want to do extra configuration to be able to use relative path. For example, in the case of PyCharm, you need to mark the current working directory as _Sources Root_.\n",
    "- Absolute path: are complete and fixed"
   ],
   "id": "c6a91b871a8e0702"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T15:01:10.133669Z",
     "start_time": "2026-02-23T15:01:10.127262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "best_selling_books = pd.read_csv('data/data_reading_path/best_selling_books_2023_2025.csv')\n",
    "\n",
    "print(\"DataFrame loaded from CSV:\\n\")\n",
    "best_selling_books.head()"
   ],
   "id": "8c4aa064db89059d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded from CSV:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                           Book name  \\\n",
       "0  Atomic Habits: An Easy & Proven Way to Build G...   \n",
       "1    Iron Flame (Standard Edition) (The Empyrean, 2)   \n",
       "2                                              Spare   \n",
       "3                                        Fourth Wing   \n",
       "4                                    The Woman in Me   \n",
       "\n",
       "                             Author              Rating  reviews count  \\\n",
       "0                       James Clear  4.8 out of 5 stars         145747   \n",
       "1                    Rebecca Yarros  4.7 out of 5 stars         395512   \n",
       "2  Prince Harry  The Duke of Sussex  4.5 out of 5 stars         116101   \n",
       "3                    Rebecca Yarros  4.8 out of 5 stars         472618   \n",
       "4                    Britney Spears  4.4 out of 5 stars          51520   \n",
       "\n",
       "        form    price Reading age  Print Length Publishing date  \\\n",
       "0  Hardcover  $18.88          NaN         320.0      16/10/2018   \n",
       "1  Hardcover  $11.05          NaN         640.0         7/11/23   \n",
       "2  Hardcover  $11.99          NaN         416.0       10-Jan-23   \n",
       "3  Paperback  $13.62          NaN         544.0      17/09/2024   \n",
       "4  Hardcover  $11.37          NaN         288.0       24-Oct-23   \n",
       "\n",
       "                          Genre id_2023 id_2024 id_2025  \n",
       "0              Self-Improvement      #1      #3      #6  \n",
       "1  Fiction & Action & Adventure      #2     #13     NaN  \n",
       "2         Biographies & Memoirs      #3     NaN     NaN  \n",
       "3  Fiction & Action & Adventure      #4     #16     #76  \n",
       "4         Biographies & Memoirs      #5     NaN     NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rating</th>\n",
       "      <th>reviews count</th>\n",
       "      <th>form</th>\n",
       "      <th>price</th>\n",
       "      <th>Reading age</th>\n",
       "      <th>Print Length</th>\n",
       "      <th>Publishing date</th>\n",
       "      <th>Genre</th>\n",
       "      <th>id_2023</th>\n",
       "      <th>id_2024</th>\n",
       "      <th>id_2025</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atomic Habits: An Easy &amp; Proven Way to Build G...</td>\n",
       "      <td>James Clear</td>\n",
       "      <td>4.8 out of 5 stars</td>\n",
       "      <td>145747</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>$18.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.0</td>\n",
       "      <td>16/10/2018</td>\n",
       "      <td>Self-Improvement</td>\n",
       "      <td>#1</td>\n",
       "      <td>#3</td>\n",
       "      <td>#6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iron Flame (Standard Edition) (The Empyrean, 2)</td>\n",
       "      <td>Rebecca Yarros</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "      <td>395512</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>$11.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>640.0</td>\n",
       "      <td>7/11/23</td>\n",
       "      <td>Fiction &amp; Action &amp; Adventure</td>\n",
       "      <td>#2</td>\n",
       "      <td>#13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spare</td>\n",
       "      <td>Prince Harry  The Duke of Sussex</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>116101</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>$11.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416.0</td>\n",
       "      <td>10-Jan-23</td>\n",
       "      <td>Biographies &amp; Memoirs</td>\n",
       "      <td>#3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fourth Wing</td>\n",
       "      <td>Rebecca Yarros</td>\n",
       "      <td>4.8 out of 5 stars</td>\n",
       "      <td>472618</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>$13.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>544.0</td>\n",
       "      <td>17/09/2024</td>\n",
       "      <td>Fiction &amp; Action &amp; Adventure</td>\n",
       "      <td>#4</td>\n",
       "      <td>#16</td>\n",
       "      <td>#76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Woman in Me</td>\n",
       "      <td>Britney Spears</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>51520</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>$11.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288.0</td>\n",
       "      <td>24-Oct-23</td>\n",
       "      <td>Biographies &amp; Memoirs</td>\n",
       "      <td>#5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T15:02:58.225633Z",
     "start_time": "2026-02-23T15:02:58.220843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Some of the parameters you can pass\n",
    "\n",
    "best_selling_books = pd.read_csv('data/data_reading_path/best_selling_books_2023_2025.csv',\n",
    "                                 # usecols: Subset of columns to select\n",
    "                                 usecols=['Book name','Author','reviews count'],\n",
    "                                 # dtype: dtype or dictionary of dtypes\n",
    "                                 dtype={'Book name': str, 'reviews count': int},\n",
    "                                 # nrows: number of rows to read. I would read a small chunk just to inspect data if the file is large\n",
    "                                 nrows=10,\n",
    "                                 )\n",
    "\n",
    "print(\"DataFrame loaded from CSV:\\n\")\n",
    "best_selling_books\n"
   ],
   "id": "353484743fb21361",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded from CSV:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                           Book name  \\\n",
       "0  Atomic Habits: An Easy & Proven Way to Build G...   \n",
       "1    Iron Flame (Standard Edition) (The Empyrean, 2)   \n",
       "2                                              Spare   \n",
       "3                                        Fourth Wing   \n",
       "4                                    The Woman in Me   \n",
       "5                      Lessons in Chemistry: A Novel   \n",
       "6                               The 48 Laws of Power   \n",
       "7  The Body Keeps the Score: Brain, Mind, and Bod...   \n",
       "8       It Starts with Us: A Novel (It Ends with Us)   \n",
       "9          Outlive: The Science and Art of Longevity   \n",
       "\n",
       "                             Author  reviews count  \n",
       "0                       James Clear         145747  \n",
       "1                    Rebecca Yarros         395512  \n",
       "2  Prince Harry  The Duke of Sussex         116101  \n",
       "3                    Rebecca Yarros         472618  \n",
       "4                    Britney Spears          51520  \n",
       "5                     Bonnie Garmus         322650  \n",
       "6                     Robert Greene          87375  \n",
       "7          Bessel van der Kolk M.D.          82564  \n",
       "8                    Colleen Hoover         228242  \n",
       "9                    Peter Attia MD          19946  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author</th>\n",
       "      <th>reviews count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atomic Habits: An Easy &amp; Proven Way to Build G...</td>\n",
       "      <td>James Clear</td>\n",
       "      <td>145747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iron Flame (Standard Edition) (The Empyrean, 2)</td>\n",
       "      <td>Rebecca Yarros</td>\n",
       "      <td>395512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spare</td>\n",
       "      <td>Prince Harry  The Duke of Sussex</td>\n",
       "      <td>116101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fourth Wing</td>\n",
       "      <td>Rebecca Yarros</td>\n",
       "      <td>472618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Woman in Me</td>\n",
       "      <td>Britney Spears</td>\n",
       "      <td>51520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lessons in Chemistry: A Novel</td>\n",
       "      <td>Bonnie Garmus</td>\n",
       "      <td>322650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The 48 Laws of Power</td>\n",
       "      <td>Robert Greene</td>\n",
       "      <td>87375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Body Keeps the Score: Brain, Mind, and Bod...</td>\n",
       "      <td>Bessel van der Kolk M.D.</td>\n",
       "      <td>82564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It Starts with Us: A Novel (It Ends with Us)</td>\n",
       "      <td>Colleen Hoover</td>\n",
       "      <td>228242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Outlive: The Science and Art of Longevity</td>\n",
       "      <td>Peter Attia MD</td>\n",
       "      <td>19946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d21e0ecf22708aa2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Read Excel files\n",
    "\n",
    "Before you read an Excel file, make sure openpyxl package is installed. openpyxl is a Python library to read/write Excel 2010 xlsx/xlsm/xltx/xltm files."
   ],
   "id": "c258e034913448fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T15:05:02.183610Z",
     "start_time": "2026-02-23T15:05:01.279177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "tools = pd.read_excel('data/data_reading_path/ONET_data_tools_used.xlsx',\n",
    "                      sheet_name=0, # default 0, or a str of the name, or a list of the names\n",
    "                      )\n",
    "\n",
    "print(\"DataFrame loaded from xlsx files:\\n\")\n",
    "tools.head()\n"
   ],
   "id": "f6f823dd46e2f1c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded from xlsx files:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  O*NET-SOC Code             Title                          Example  \\\n",
       "0     11-1011.00  Chief Executives               10-key calculators   \n",
       "1     11-1011.00  Chief Executives                Desktop computers   \n",
       "2     11-1011.00  Chief Executives                 Laptop computers   \n",
       "3     11-1011.00  Chief Executives               Personal computers   \n",
       "4     11-1011.00  Chief Executives  Personal digital assistants PDA   \n",
       "\n",
       "   Commodity Code                               Commodity Title  \n",
       "0        44101809                            Desktop calculator  \n",
       "1        43211507                              Desktop computer  \n",
       "2        43211503                             Notebook computer  \n",
       "3        43211508                             Personal computer  \n",
       "4        43211504  Personal digital assistant PDAs or organizer  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Example</th>\n",
       "      <th>Commodity Code</th>\n",
       "      <th>Commodity Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>10-key calculators</td>\n",
       "      <td>44101809</td>\n",
       "      <td>Desktop calculator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>Desktop computers</td>\n",
       "      <td>43211507</td>\n",
       "      <td>Desktop computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>Laptop computers</td>\n",
       "      <td>43211503</td>\n",
       "      <td>Notebook computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>Personal computers</td>\n",
       "      <td>43211508</td>\n",
       "      <td>Personal computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>Personal digital assistants PDA</td>\n",
       "      <td>43211504</td>\n",
       "      <td>Personal digital assistant PDAs or organizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T15:04:41.477426Z",
     "start_time": "2026-02-23T15:04:41.359688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If you don't know the sheet names and wanted to inspect them, you could do the following:\n",
    "import pandas as pd\n",
    "\n",
    "file_to_check = pd.ExcelFile('data/data_reading_path/ONET_data_tools_used.xlsx')\n",
    "\n",
    "print(file_to_check.sheet_names)"
   ],
   "id": "a0e00b2e38989523",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tools Used']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2aacb61549d437f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c4014a56d8f70e87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Read JSON files\n",
    "JSON (JavaScript Object Notation) is a lightweight, text-based, language-independent data-interchange format designed to be human-readable and machine-parsable."
   ],
   "id": "3840793976d96503"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T15:05:20.413214Z",
     "start_time": "2026-02-23T15:05:20.407215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read the json file\n",
    "\n",
    "iris = pd.read_json('data/data_reading_path/iris.json')\n",
    "\n",
    "print(\"DataFrame loaded from JSON:\\n\")\n",
    "print(iris.head())"
   ],
   "id": "c8a8bd9fabed2829",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded from JSON:\n",
      "\n",
      "   sepalLength  sepalWidth  petalLength  petalWidth species\n",
      "0          5.1         3.5          1.4         0.2  setosa\n",
      "1          4.9         3.0          1.4         0.2  setosa\n",
      "2          4.7         3.2          1.3         0.2  setosa\n",
      "3          4.6         3.1          1.5         0.2  setosa\n",
      "4          5.0         3.6          1.4         0.2  setosa\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e6def18e159f062d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pickling\n",
    "Pickling can be useful to preserve Python obejects\n",
    "\n",
    "### Example 1: pickling of basic Python objects"
   ],
   "id": "25f9676f66dd5437"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame where some cells contain lists and dictionaries\n",
    "# This is common when working with JSON, APIs, or semi-structured data\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"species\": [\"Sparrow\", \"Robin\", \"Blue Jay\"],\n",
    "\n",
    "    # Each cell in this column contains a LIST\n",
    "    \"observed_colors\": [\n",
    "        [\"brown\", \"gray\"],\n",
    "        [\"red\", \"brown\"],\n",
    "        [\"blue\", \"white\", \"black\"]\n",
    "    ],\n",
    "\n",
    "    # Each cell in this column contains a DICTIONARY\n",
    "    \"measurements\": [\n",
    "        {\"weight_g\": 24, \"wingspan_cm\": 20},\n",
    "        {\"weight_g\": 77, \"wingspan_cm\": 31},\n",
    "        {\"weight_g\": 100, \"wingspan_cm\": 43}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"DataFrame with lists and dictionaries in cells:\")\n",
    "print(df)\n"
   ],
   "id": "3c8dfadee9a243e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# save as a pickle file and a csv file\n",
    "\n",
    "df.to_pickle('data/data_writing_path/birds_df.pkl')\n",
    "df.to_csv('data/data_writing_path/birds_df.csv', index=False) # index=False prevent creating a new index column\n",
    "print(\"DataFrame saved to pickle and csv.\\n\")\n"
   ],
   "id": "f65a0f492afd15ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's read the csv file and the pickle file\n",
    "\n",
    "birds_df_csv = pd.read_csv('data/data_writing_path/birds_df.csv')\n",
    "print(\"DataFrame loaded from csv:\")\n",
    "print(birds_df_csv)\n",
    "\n",
    "\n",
    "birds_df_pickled = pd.read_pickle('data/data_writing_path/birds_df.pkl')\n",
    "print(\"\\nDataFrame loaded from pickle:\")\n",
    "print(birds_df_pickled)"
   ],
   "id": "d464fea6fd0d193f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Info of Dataframe loaded from csv:\")\n",
    "print(birds_df_csv.info())\n",
    "\n",
    "print(\"\\nInfo of Dataframe loaded from pickle:\")\n",
    "print(birds_df_pickled.info())"
   ],
   "id": "2bd7a41a831d304b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'The original dataframe contains list and dictionary columns, for example,\\n'\n",
    "      f'sparrow\\'s observed colors is: {(colors:=(df[df[\"species\"] == \"Sparrow\"][\"observed_colors\"].iloc[0]))}, and the type is {type(colors)}.')\n",
    "print(f\"\\nHowever, the dataframe we read back from the CSV file, sparrow's observed color is \"\n",
    "      f\"{(new_colors:=(birds_df_csv[birds_df_csv['species'] == 'Sparrow']['observed_colors'].iloc[0]))}, and the type is {type(new_colors)}.\")\n",
    "\n",
    "print(f\"\\nOn the other hand, in the dataframe we read back from the pickle file, it preserves the types. The sparrow's colors include {(pickle_colors:=(birds_df_pickled[birds_df_pickled['species']=='Sparrow']['observed_colors'].iloc[0]))}, and the type is {type(pickle_colors)}.\")"
   ],
   "id": "3446e045973d2f3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If you have columns in your CSV file that are supposed to be Python types other than integer, float, or string, you can use ast.literal_eval. ast stands for Abstract Syntax Tree\n",
    "import ast\n",
    "\n",
    "literal_evaled_df = pd.read_csv('data/data_writing_path/birds_df.csv')\n",
    "\n",
    "# Convert the string column to a list column using .apply()\n",
    "literal_evaled_df['observed_colors'] = literal_evaled_df['observed_colors'].apply(ast.literal_eval)\n",
    "literal_evaled_df['measurements'] = literal_evaled_df['measurements'].apply(ast.literal_eval)\n"
   ],
   "id": "5b448c48ad9cd6e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(type(literal_evaled_df['observed_colors'].iloc[0]))",
   "id": "4aa2e69bed7bf270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c6137fdbf86a8e06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9ebd2341166a854b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "edf95c2f2722c977",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Read only part of the file\n",
    "If your data file is large, you can use `nrows` to control how many rows you read as a dataframe"
   ],
   "id": "f2bc1e80a9c97ddf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "chocolate_df = pd.read_csv('data/data_reading_path/chocolate_sales.csv', nrows=2)\n",
    "\n",
    "print(chocolate_df)"
   ],
   "id": "d2efa9fe03652093",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1b533e223cef0150",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Chunking\n",
    "To read a large file in chunks with pandas, you use the `chunksize` parameter in a file reading function like `pd.read_csv()`. This returns an iterator that yields smaller DataFrame objects (chunks) one by one, allowing you to process the data with limited memory.\n",
    "\n",
    "For example, you can read the file chunk by chunk and conduct some operations chunk by chunk, which takes much smaller memories."
   ],
   "id": "b5ad79ddb3286777"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T15:11:44.791400Z",
     "start_time": "2026-02-23T15:11:44.782772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_size = 500\n",
    "\n",
    "chunks = []\n",
    "\n",
    "counter = 0\n",
    "for chunk in pd.read_csv('data/data_reading_path/chocolate_sales.csv',\n",
    "                         chunksize=chunk_size):\n",
    "    print(f\"Chunk {counter} index: {chunk.index.min()} ~ {chunk.index.max()}, shape {chunk.shape}\")\n",
    "    # You can conduct some operations by chunk\n",
    "    counter += 1\n",
    "    chunks.append(chunk)\n",
    "\n",
    "chocolate_df = pd.concat(chunks)\n",
    "\n",
    "print(\"\\nFinal dataframe:\")\n",
    "print(chocolate_df.head())"
   ],
   "id": "41ac962bd59fb38b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 index: 0 ~ 499, shape (500, 6)\n",
      "Chunk 1 index: 500 ~ 999, shape (500, 6)\n",
      "Chunk 2 index: 1000 ~ 1499, shape (500, 6)\n",
      "Chunk 3 index: 1500 ~ 1999, shape (500, 6)\n",
      "Chunk 4 index: 2000 ~ 2499, shape (500, 6)\n",
      "Chunk 5 index: 2500 ~ 2999, shape (500, 6)\n",
      "Chunk 6 index: 3000 ~ 3281, shape (282, 6)\n",
      "\n",
      "Final dataframe:\n",
      "     Sales Person    Country              Product        Date      Amount  \\\n",
      "0  Jehu Rudeforth         UK      Mint Chip Choco  04/01/2022   $5,320.00   \n",
      "1     Van Tuxwell      India        85% Dark Bars  01/08/2022   $7,896.00   \n",
      "2    Gigi Bohling      India  Peanut Butter Cubes  07/07/2022   $4,501.00   \n",
      "3    Jan Morforth  Australia  Peanut Butter Cubes  27/04/2022  $12,726.00   \n",
      "4  Jehu Rudeforth         UK  Peanut Butter Cubes  24/02/2022  $13,685.00   \n",
      "\n",
      "   Boxes Shipped  \n",
      "0            180  \n",
      "1             94  \n",
      "2             91  \n",
      "3            342  \n",
      "4            184  \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b715a6500d50387",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a37ec9f0416021a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "84bdb80c44f59de7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inspect Data",
   "id": "1ab524206d566805"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/data_reading_path/chocolate_sales.csv')\n",
    "\n",
    "print(\"Preview first 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nPreview last 5 rows:\")\n",
    "print(df.tail())\n",
    "\n",
    "print(\"\\nBasic information about the DataFrame:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nDataFrame shape (rows, columns):\")\n",
    "print(df.shape)\n",
    "\n",
    "print(\"\\nEstimated memory usage:\")\n",
    "print(df.memory_usage(deep=True).sum(), \"bytes\")\n"
   ],
   "id": "fd7b5d81d5a1b92c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3c7b6bc0cf6e7d65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Writing data to files\n",
   "id": "78c317ffc9bed3a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "save_path = \"data/data_writing_path\"\n",
    "\n",
    "# Create a simple DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"age\": [25, 32, 29],\n",
    "    \"city\": [\"New York\", \"Los Angeles\", \"Chicago\"],\n",
    "    \"salary\": [70000, 85000, 78000]\n",
    "})\n",
    "\n",
    "print(df)"
   ],
   "id": "681ef31d388dcda7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Write to CSV\n",
    "df.to_csv(f\"{save_path}/employees.csv\", index=False)\n"
   ],
   "id": "c634363716b98ce6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Write to Excel\n",
    "# Again, it requires openpyxl package (usually already installed)\n",
    "\n",
    "df.to_excel(f\"{save_path}/employees.xlsx\", index=False)\n"
   ],
   "id": "a40070c3a729c6bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Write to JSON\n",
    "# orient=\"records\" makes a list of dictionaries (very common in APIs)\n",
    "# indent=2 makes it human-readable\n",
    "\n",
    "df.to_json(f\"{save_path}/employees.json\", orient=\"records\", indent=2)\n"
   ],
   "id": "40b0bb7602fa097f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Write to Pickle\n",
    "df.to_pickle(f\"{save_path}/employees.pkl\")\n"
   ],
   "id": "41faea7fdf2833de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "files = [\n",
    "    f\"{save_path}/employees.csv\",\n",
    "    f\"{save_path}/employees.xlsx\",\n",
    "    f\"{save_path}/employees.json\",\n",
    "    f\"{save_path}/employees.pkl\"\n",
    "]\n",
    "\n",
    "for f in files:\n",
    "    print(f\"{f}: {os.path.getsize(f)} bytes\")\n"
   ],
   "id": "c11c39a91c76451b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e43a11febdabecb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# [Optional] Polars\n",
    "\n",
    "Polars (linked here) is an open-source library for data manipulation, known for being one the fastest data processing solution on a single machine.\n"
   ],
   "id": "c28d500fd32baa72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "n = 5_000_000\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "data = {\n",
    "    \"user_id\": np.random.randint(1, 100_000, n),\n",
    "    \"category\": np.random.choice([\"A\", \"B\", \"C\", \"D\", \"E\"], n),\n",
    "    \"price\": np.random.gamma(2, 50, n),\n",
    "    \"quantity\": np.random.randint(1, 5, n),\n",
    "    \"discount\": np.random.rand(n)\n",
    "}\n",
    "\n",
    "df_pd = pd.DataFrame(data)\n",
    "df_pl = pl.DataFrame(data)\n",
    "\n",
    "print(\"Pandas shape:\", df_pd.shape)\n",
    "print(\"Polars shape:\", df_pl.shape)\n"
   ],
   "id": "970de3504b698ad7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# let's do a series of computation:\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df_pd[\"total\"] = df_pd[\"price\"] * df_pd[\"quantity\"]\n",
    "df_pd[\"revenue\"] = df_pd[\"total\"] * (1 - df_pd[\"discount\"])\n",
    "\n",
    "result_pd = (\n",
    "    df_pd\n",
    "    .groupby([\"user_id\", \"category\"])\n",
    "    .agg(\n",
    "        total_revenue=(\"revenue\", \"sum\"),\n",
    "        avg_price=(\"price\", \"mean\"),\n",
    "        total_quantity=(\"quantity\", \"sum\")\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values(\"total_revenue\", ascending=False)\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(\"Pandas pipeline time:\", end - start)\n"
   ],
   "id": "762dc23fb14822be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "\n",
    "result_pl = (\n",
    "    df_pl\n",
    "    .with_columns([\n",
    "        (pl.col(\"price\") * pl.col(\"quantity\")).alias(\"total\"),\n",
    "        (pl.col(\"price\") * pl.col(\"quantity\") * (1 - pl.col(\"discount\"))).alias(\"revenue\")\n",
    "    ])\n",
    "    .group_by([\"user_id\", \"category\"])\n",
    "    .agg([\n",
    "        pl.col(\"revenue\").sum().alias(\"total_revenue\"),\n",
    "        pl.col(\"price\").mean().alias(\"avg_price\"),\n",
    "        pl.col(\"quantity\").sum().alias(\"total_quantity\")\n",
    "    ])\n",
    "    .sort(\"total_revenue\", descending=True)\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(\"Polars eager pipeline time:\", end - start)\n"
   ],
   "id": "fa0e938cf49d1a8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "\n",
    "result_lazy = (\n",
    "    df_pl.lazy()\n",
    "    .with_columns([\n",
    "        (pl.col(\"price\") * pl.col(\"quantity\")).alias(\"total\"),\n",
    "        (pl.col(\"price\") * pl.col(\"quantity\") * (1 - pl.col(\"discount\"))).alias(\"revenue\")\n",
    "    ])\n",
    "    .group_by([\"user_id\", \"category\"])\n",
    "    .agg([\n",
    "        pl.col(\"revenue\").sum().alias(\"total_revenue\"),\n",
    "        pl.col(\"price\").mean().alias(\"avg_price\"),\n",
    "        pl.col(\"quantity\").sum().alias(\"total_quantity\")\n",
    "    ])\n",
    "    .sort(\"total_revenue\", descending=True)\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(\"Polars lazy pipeline time:\", end - start)\n"
   ],
   "id": "499dc81048681148",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b85d0b33a155c0df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# [optional] tqdm - progress bar",
   "id": "b9bce717b15ec03f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T15:19:11.793603Z",
     "start_time": "2026-02-23T15:19:08.655525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Simulate a slow task\n",
    "for i in tqdm(range(20)):\n",
    "    time.sleep(0.15)"
   ],
   "id": "4c5f27a4109da68c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  6.47it/s]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T15:19:28.213030Z",
     "start_time": "2026-02-23T15:19:25.100434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "for i in tqdm(\n",
    "    range(20),\n",
    "    desc=\"Downloading\",\n",
    "    total=20,\n",
    "    ncols=500,\n",
    "    unit=\"file\",\n",
    "    colour=\"blue\"\n",
    "):\n",
    "    time.sleep(0.15)\n"
   ],
   "id": "c1086fa15c622d50",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading:   0%|                                                                                            …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad25fd4c993341ba8477223ab5d19717"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T15:19:36.218486Z",
     "start_time": "2026-02-23T15:19:36.213782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Create a larger DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"numbers\": np.random.randint(1, 100, size=100)\n",
    "})\n",
    "\n",
    "df.head()\n"
   ],
   "id": "76175e9493693fb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   numbers\n",
       "0       64\n",
       "1       40\n",
       "2       55\n",
       "3        5\n",
       "4        3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T15:19:52.787485Z",
     "start_time": "2026-02-23T15:19:47.431397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply Function WITHOUT tqdm\n",
    "\n",
    "def slow_square(x):\n",
    "    time.sleep(0.05)\n",
    "    return x ** 2\n",
    "\n",
    "df[\"squared\"] = df[\"numbers\"].apply(slow_square)\n"
   ],
   "id": "1ae639525069ec1c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T15:20:15.975991Z",
     "start_time": "2026-02-23T15:20:10.590674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply Function WITH tqdm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"Processing Dataframe for EST 389: \")  # Enable progress_apply\n",
    "\n",
    "df[\"squared\"] = df[\"numbers\"].progress_apply(slow_square)\n"
   ],
   "id": "ccfc5dc963527fa9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Dataframe for EST 389: 100%|██████████| 100/100 [00:05<00:00, 18.58it/s]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "36f21ce395426d25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c2bbb6adf6d2fa15",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
